{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1: Scraping (PLEASE IGNORE THIS)\n"
      ],
      "metadata": {
        "id": "pBmtNfZ-rHf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google_play_scraper\n",
        "from google_play_scraper import app, Sort, reviews\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"MyAppDescriptions.csv\")\n",
        "package_names = data['Package Name']\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[0], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[0], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app1 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app1.to_csv(package_names[0] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[1], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[1], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app2 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app2.to_csv(package_names[1] + '.csv')\n",
        "\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[2], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[2], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app3 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app3.to_csv(package_names[2] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[3], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[3], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app4 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app4.to_csv(package_names[3] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[4], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[4], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app5 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app5.to_csv(package_names[4] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[5], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[5], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app6 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app6.to_csv(package_names[5] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[6], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[6], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app7 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app7.to_csv(package_names[6] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[7], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[7], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app8 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app8.to_csv(package_names[7] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[8], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[8], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app9 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app9.to_csv(package_names[8] + '.csv')\n",
        "\n",
        "content = []\n",
        "reviews_list, _ = reviews(package_names[9], lang='en', country='us', sort=Sort.NEWEST, count=10000)\n",
        "for review in reviews_list:\n",
        "  review_data = [package_names[9], review['userName'], review['content'], review['score']]\n",
        "  content.append(review_data)\n",
        "app10 = pd.DataFrame(content, columns=['Package name', 'Reviewer name', 'Review','Rating'])\n",
        "app10.to_csv(package_names[9] + '.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b15qmY8Mr5Kn",
        "outputId": "6c702b89-d767-47c6-ac4e-d0e274ade26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google_play_scraper in /usr/local/lib/python3.8/dist-packages (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Preprocessing\n",
        "## Bonus Task\n",
        "Yes, the choice of stop words does have an impact on the analysis of reviews. The idea behind removing stop words is to help us analyze the more interesting words during an analysis. NLTK has a list of stopwords, as mentioned in the question, and that helps us in bettering our analysis by focusing on the more interesting words.\n",
        "\n",
        "The risk of using a non customized list of stopwords is that they may affect the analysis of the reviews. A word might be interesting enough to change the analysis of a review and if that word happened to be on the stopwords list, then the review can change their polarity and end up on the positive or negative side when its not supposed to be."
      ],
      "metadata": {
        "id": "d0XnAORGr8Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import csv\n",
        "!pip install num2words\n",
        "from num2words import num2words\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "def num_to_words(review):\n",
        "    text_split = review.split()\n",
        "    for i in range(len(text_split)):\n",
        "        if text_split[i].isdigit():\n",
        "            text_split[i] = num2words(text_split[i])\n",
        "    numbers_to_words = ' '.join(text_split)\n",
        "    return numbers_to_words\n",
        "\n",
        "data = pd.read_csv(\"MyAppDescriptions.csv\")\n",
        "package_names = data['Package Name']\n",
        "\n",
        "for j in range(package_names.size):\n",
        "  reviews_list = pd.read_csv(package_names[j] + '.csv')\n",
        "  reviews = reviews_list['Review']\n",
        "  for i in range(reviews.size):\n",
        "    reviews[i] = re.sub(r'[^\\w\\s]', '', str(reviews[i]))\n",
        "    reviews[i] = reviews[i].strip()\n",
        "    reviews[i] = reviews[i].lower()\n",
        "    reviews[i] = deEmojify(reviews[i])\n",
        "    reviews[i] = re.sub(r'\\s{2}', ' ', str(reviews[i]))\n",
        "    reviews[i] = num_to_words(reviews[i])\n",
        "    reviews[i] = remove_stopwords(reviews[i])\n",
        "    wnl = WordNetLemmatizer()\n",
        "    reviews[i] = wnl.lemmatize(reviews[i])\n",
        "  reviews_list.to_csv(package_names[j] + '.csv')\n",
        "\n",
        "# Output 15 pre-processed reviews (TODO)\n",
        "review_list = pd.read_csv('com.evernote.csv')\n",
        "reviews = reviews_list['Review']\n",
        "for review in reviews[200:215]:\n",
        "  print(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra5AnmUBsAgJ",
        "outputId": "2ab350a7-37a9-442e-e839-222ec242bf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.8/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from num2words) (0.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fits need perfectly friendly effective\n",
            "app user friendly\n",
            "working best\n",
            "nice app\n",
            "favorite calendar app\n",
            "app didnt meet expectations organizer layout features samsung calendar arent features unique useful use app\n",
            "cause lil kid step tie\n",
            "finally calendar like real agenda planner ill actually use business personal schedule better organized purchased pro wouldnt fair low price unheard anymore good job ill exploring love far\n",
            "ok lil improvement s neended slowly\n",
            "given star having trouble widget lately wont sync update currrent date installed issue frxed\n",
            "love app easy use integrates nicely\n",
            "application features brand applications addition week glance overview display unique feature reason selected use application\n",
            "good communication skills\n",
            "great app\n",
            "friendly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Sentiment Analysis\n",
        "## Discussion (Part V)\n",
        "Textblob sentiment analyzer returns two properties for a given input sentence:\n",
        "- Polarity is a float that lies between [-1,1], -1 indicates negative sentiment and +1 indicates positive sentiments.\n",
        "- Subjectivity is also a float that lies in the range of [0,1]. Subjective sentences generally refer to opinion, emotion, or judgment.\n",
        "\n",
        "Vader uses a list of lexical features (e.g. word) which are labeled as positive or negative according to their semantic orientation to calculate the text sentiment. Vader sentiment returns the probability of a given input sentence to be positive, negative, and neutral.\n",
        "\n",
        "Vader is optimized for social media data and can yield good results when used with data from Twitter, Facebook, etc. Vader shows the positive, neutral and negative and compound probabilities of the data provided to it, which is why i would use Vader instead of Textblob."
      ],
      "metadata": {
        "id": "KPJKBjnlsCAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "data = pd.read_csv(\"MyAppDescriptions.csv\")\n",
        "package_names = data['Package Name']\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "textblob_content = []\n",
        "vader_content = []\n",
        "for i in range(package_names.size):\n",
        "  reviews_list = pd.read_csv(package_names[i] + '.csv')\n",
        "  reviews = reviews_list['Review']\n",
        "  for j in range(reviews.size):\n",
        "    review = TextBlob(str(reviews[j]))\n",
        "    textblob_content.append([package_names[i], reviews[j], review.sentiment[0]])\n",
        "    vader_content.append([package_names[i], reviews[j], analyzer.polarity_scores(str(reviews[j]))['compound']])\n",
        "textblob_sentiments = pd.DataFrame(textblob_content, columns=['App’s package name', 'Review', 'Polarity'])\n",
        "textblob_sentiments.to_csv('textblob.csv')\n",
        "print(\"----------TEXTBLOB TABLE-------------------\")\n",
        "print(textblob_sentiments)\n",
        "print(\"-------------------------------------------\")\n",
        "\n",
        "vader_sentiments = pd.DataFrame(textblob_content, columns=['App’s package name', 'Review', 'Polarity'])\n",
        "vader_sentiments.to_csv('vader.csv')\n",
        "print(\"----------VADER TABLE-------------------\")\n",
        "print(vader_sentiments)\n",
        "print(\"-------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAi7f-EAX4Uk",
        "outputId": "81f2c3c8-193e-4866-bc58-4dbce72cb9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "----------TEXTBLOB TABLE-------------------\n",
            "                    App’s package name  \\\n",
            "0      com.simplemobiletools.notes.pro   \n",
            "1      com.simplemobiletools.notes.pro   \n",
            "2      com.simplemobiletools.notes.pro   \n",
            "3      com.simplemobiletools.notes.pro   \n",
            "4      com.simplemobiletools.notes.pro   \n",
            "...                                ...   \n",
            "30652        ru.infteh.organizer.trial   \n",
            "30653        ru.infteh.organizer.trial   \n",
            "30654        ru.infteh.organizer.trial   \n",
            "30655        ru.infteh.organizer.trial   \n",
            "30656        ru.infteh.organizer.trial   \n",
            "\n",
            "                                                  Review  Polarity  \n",
            "0      false advertising widget add multiple shows thing -0.200000  \n",
            "1      bought alternate app wasnt par update good rep...  0.350000  \n",
            "2                             like better edit list item  0.500000  \n",
            "3      si vous cherchez une application prise notes n...  0.000000  \n",
            "4      works described sent email asking question add...  0.000000  \n",
            "...                                                  ...       ...  \n",
            "30652  love integrates google calendar wish tabs like...  0.421429  \n",
            "30653      perfect needed looking forward future updates  0.500000  \n",
            "30654  started hooked love format ability information...  0.311111  \n",
            "30655                 dont widget opened add widget love  0.500000  \n",
            "30656  в виджете надо сделать прокрутку а то не удобн...  0.000000  \n",
            "\n",
            "[30657 rows x 3 columns]\n",
            "-------------------------------------------\n",
            "----------VADER TABLE-------------------\n",
            "                    App’s package name  \\\n",
            "0      com.simplemobiletools.notes.pro   \n",
            "1      com.simplemobiletools.notes.pro   \n",
            "2      com.simplemobiletools.notes.pro   \n",
            "3      com.simplemobiletools.notes.pro   \n",
            "4      com.simplemobiletools.notes.pro   \n",
            "...                                ...   \n",
            "30652        ru.infteh.organizer.trial   \n",
            "30653        ru.infteh.organizer.trial   \n",
            "30654        ru.infteh.organizer.trial   \n",
            "30655        ru.infteh.organizer.trial   \n",
            "30656        ru.infteh.organizer.trial   \n",
            "\n",
            "                                                  Review  Polarity  \n",
            "0      false advertising widget add multiple shows thing -0.200000  \n",
            "1      bought alternate app wasnt par update good rep...  0.350000  \n",
            "2                             like better edit list item  0.500000  \n",
            "3      si vous cherchez une application prise notes n...  0.000000  \n",
            "4      works described sent email asking question add...  0.000000  \n",
            "...                                                  ...       ...  \n",
            "30652  love integrates google calendar wish tabs like...  0.421429  \n",
            "30653      perfect needed looking forward future updates  0.500000  \n",
            "30654  started hooked love format ability information...  0.311111  \n",
            "30655                 dont widget opened add widget love  0.500000  \n",
            "30656  в виджете надо сделать прокрутку а то не удобн...  0.000000  \n",
            "\n",
            "[30657 rows x 3 columns]\n",
            "-------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4\n",
        "\n",
        "**PLEASE NOTE THAT I HAVE USED TWO METHODS FOR EXTRACTION OF TOPICS FOR THE CONVENIENCE OF GRADING OR PEER REVIEW. I PERSONALLY BELIEVE YOU WILL LIKE THE ONE I LIKE AS WELL. I PERSONALLY USE SCIKIT PACKAGE AND NOT GENSIM PACKAGE BECAUSE ITS MORE CLEAN AND IT GIVES MORE VARIETY WHILE SEPARATING THE USELESS WORDS LIKE APP. BUT JUST IN CASE YOU WANTED TO KNOW WHY I LIKED THE SCIKIT ONE, I HAVE INCLUDED BOTH THE METHODS**\n",
        "\n",
        "## Discussion (Part III)\n",
        "The summarized topics are very similar to the app features as well as the bigrams and trigrams. Lets talk about the app features first. The app features are just main features of the app that has been extracted from the google play page. The summarized topics are from the reviews i extracted from the google play page. They are different because after manual inspection, I have concluded that the reviews do not relate with the features, but they actually relate with the experience users have had with the app, so for example if the app crashed multiple times, or if the user interface was very much to their liking, or if the app has been crashing a lot or if the app has been taking too long to load their data. These have nothing to do with the app features, but they are in the reviews so i believe that they do not relate with the features at all.\n",
        "\n",
        "Speaking of bigrams and trigrams, i can make the same argument. The bigrams and trigrams are extracted from the pre-processed descriptions of the apps. So the reviews will not compare or relate with the reviews at all.\n",
        "\n",
        "## Discussion (Part V)\n",
        "This is actually a pretty interesting topic. If we talk about the topics of the other apps versus the topics of the assigned app, i can say it varies. Let me explain what I mean by this.\n",
        "\n",
        "So if the reviews happen to be positive or neutral, then the topics include features of the app as well as regular reviews, for example the topics include how the files are easily accessible or how there are no ads in the app or how they have offline sync and stuff like that. They might even have suggestions like having events sync in the notes app.\n",
        "\n",
        "If the reviews are negative, then you can notice that the features are not mentioned, but the app is just criticized for how bad it really is. So they talk about how it keeps on crashing, how the ads bother them, how it takes time to load, and so on.  "
      ],
      "metadata": {
        "id": "Vmtr_MhKjsJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "reviews_list = pd.read_csv('com.evernote.csv')\n",
        "reviews = reviews_list['Review']\n",
        "\n",
        "# THIS IS FOR THE ASSIGNED APP (EVERNOTE SINCE IT HAS MORE REVIEWS ON GOOGLE PLAY THAN MICROSOFT TODO)\n",
        "all_tokens = []\n",
        "temp_tokens = []\n",
        "for review in reviews:\n",
        "  tokens = word_tokenize(str(review))\n",
        "  for token in tokens:\n",
        "    temp_tokens.append(token)\n",
        "all_tokens.append(temp_tokens)\n",
        "dictionary = gensim.corpora.Dictionary(all_tokens)\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in all_tokens]\n",
        "# for i in bow_corpus[0]:\n",
        "#     print(\"Word {} (\\\"{}\\\") appears {} time.\".format(i[0], dictionary[i[0]], i[1]))\n",
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, num_topics = 10, id2word = dictionary, passes = 10, workers = 2)\n",
        "print(\"--------------------------------------ASSIGNED APP----------------------------------\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "    print(\"\\n\")\n",
        "lda_model[bow_corpus[0]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELJxhr3ijtW5",
        "outputId": "8f3331b6-31fe-46fe-9872-7bec79c1d675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------ASSIGNED APP----------------------------------\n",
            "Topic: 0 \n",
            "Words: 0.002*\"app\" + 0.001*\"notes\" + 0.001*\"evernote\" + 0.001*\"note\" + 0.000*\"years\" + 0.000*\"use\" + 0.000*\"great\" + 0.000*\"good\" + 0.000*\"open\" + 0.000*\"version\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.002*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.001*\"evernote\" + 0.000*\"use\" + 0.000*\"good\" + 0.000*\"great\" + 0.000*\"update\" + 0.000*\"im\" + 0.000*\"like\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"evernote\" + 0.000*\"use\" + 0.000*\"note\" + 0.000*\"good\" + 0.000*\"version\" + 0.000*\"years\" + 0.000*\"time\" + 0.000*\"great\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.015*\"app\" + 0.006*\"notes\" + 0.006*\"evernote\" + 0.005*\"note\" + 0.004*\"use\" + 0.003*\"great\" + 0.003*\"good\" + 0.003*\"years\" + 0.002*\"im\" + 0.002*\"version\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.003*\"app\" + 0.001*\"evernote\" + 0.001*\"notes\" + 0.001*\"note\" + 0.001*\"update\" + 0.001*\"good\" + 0.001*\"use\" + 0.001*\"time\" + 0.001*\"version\" + 0.000*\"great\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"evernote\" + 0.000*\"note\" + 0.000*\"use\" + 0.000*\"good\" + 0.000*\"open\" + 0.000*\"update\" + 0.000*\"new\" + 0.000*\"version\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.049*\"app\" + 0.022*\"notes\" + 0.015*\"evernote\" + 0.014*\"note\" + 0.011*\"use\" + 0.009*\"good\" + 0.008*\"years\" + 0.008*\"great\" + 0.008*\"open\" + 0.007*\"update\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.002*\"app\" + 0.001*\"notes\" + 0.000*\"evernote\" + 0.000*\"note\" + 0.000*\"good\" + 0.000*\"use\" + 0.000*\"great\" + 0.000*\"like\" + 0.000*\"time\" + 0.000*\"years\"\n",
            "\n",
            "\n",
            "Topic: 8 \n",
            "Words: 0.002*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.001*\"use\" + 0.001*\"evernote\" + 0.001*\"update\" + 0.001*\"years\" + 0.000*\"im\" + 0.000*\"great\" + 0.000*\"dont\"\n",
            "\n",
            "\n",
            "Topic: 9 \n",
            "Words: 0.006*\"app\" + 0.004*\"notes\" + 0.003*\"evernote\" + 0.002*\"note\" + 0.002*\"open\" + 0.002*\"good\" + 0.001*\"years\" + 0.001*\"use\" + 0.001*\"version\" + 0.001*\"slow\"\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(6, 0.9999925)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# THIS IS FOR THE ASSIGNED APP (EVERNOTE SINCE IT HAS MORE REVIEWS ON GOOGLE PLAY THAN MICROSOFT TODO)\n",
        "all_tokens = []\n",
        "temp_tokens = []\n",
        "for review in reviews:\n",
        "  tokens = word_tokenize(str(review))\n",
        "  for token in tokens:\n",
        "    temp_tokens.append(token)\n",
        "vect = TfidfVectorizer(stop_words=stop_words,max_features=1000)\n",
        "vect_text = vect.fit_transform(temp_tokens)\n",
        "lda_model =  LatentDirichletAllocation(n_components=10, learning_method='online', random_state=42, max_iter=1)\n",
        "lda_top=lda_model.fit_transform(vect_text)\n",
        "print(\"Document 0: \")\n",
        "for i,topic in enumerate(lda_top[0]):\n",
        "  print(\"Topic \",i,\": \",topic*100,\"%\")\n",
        "\n",
        "vocab = vect.get_feature_names()\n",
        "for i, comp in enumerate(lda_model.components_):\n",
        "  vocab_comp = zip(vocab, comp)\n",
        "  sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
        "  print(\"Topic \"+str(i)+\": \")\n",
        "  for t in sorted_words:\n",
        "    print(t[0],end=\" \")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "xH_Q_iZZW8sW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392f12a9-dd6f-4551-c304-963389319f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0: \n",
            "Topic  0 :  5.000000000814233 %\n",
            "Topic  1 :  5.00000000083284 %\n",
            "Topic  2 :  5.000000000756267 %\n",
            "Topic  3 :  5.000000000841108 %\n",
            "Topic  4 :  5.000000000838635 %\n",
            "Topic  5 :  5.000000000839356 %\n",
            "Topic  6 :  5.00000000082082 %\n",
            "Topic  7 :  54.9999999924678 %\n",
            "Topic  8 :  5.000000000896561 %\n",
            "Topic  9 :  5.00000000089239 %\n",
            "Topic 0: \n",
            "evernote use im version thousand love access devices best opening \n",
            "\n",
            "Topic 1: \n",
            "notes great phone like work crashes doesnt problem know users \n",
            "\n",
            "Topic 2: \n",
            "app slow keeps long month device buggy stop ill amazing \n",
            "\n",
            "Topic 3: \n",
            "good crashing fix features working screen useful data issues unusable \n",
            "\n",
            "Topic 4: \n",
            "time android issue close things takes load home option feature \n",
            "\n",
            "Topic 5: \n",
            "ive upgrade need updates scroll bad getting right got swipe \n",
            "\n",
            "Topic 6: \n",
            "open new dont want apps months subscription worse trying going \n",
            "\n",
            "Topic 7: \n",
            "update years able try paid mobile closes crash google interface \n",
            "\n",
            "Topic 8: \n",
            "wont free anymore pay premium old latest button lost star \n",
            "\n",
            "Topic 9: \n",
            "note user account way immediately stars useless review application multiple \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# THIS IS FOR THE OTHER COMPETITOR AND SIMILAR APPS\n",
        "data = pd.read_csv(\"MyAppDescriptions.csv\")\n",
        "package_names = data['Package Name']\n",
        "\n",
        "every_token = []\n",
        "temporary_tokens = []\n",
        "for name in package_names:\n",
        "  if 'com.evernote' in name:\n",
        "    continue\n",
        "  else:\n",
        "    temporary_tokens = []\n",
        "    cs_review_list = pd.read_csv(name + '.csv')\n",
        "    cs_reviews = cs_review_list['Review']\n",
        "    for cs_review in cs_reviews:\n",
        "      cs_tokens = word_tokenize(str(cs_review))\n",
        "      for cs_token in cs_tokens:\n",
        "        temporary_tokens.append(cs_token)\n",
        "    every_token.append(temporary_tokens)\n",
        "    cs_dictionary = gensim.corpora.Dictionary(every_token)\n",
        "    cs_bow_corpus = [cs_dictionary.doc2bow(doc) for doc in every_token]\n",
        "\n",
        "    cs_lda_model = gensim.models.LdaMulticore(cs_bow_corpus, num_topics=5, id2word=cs_dictionary, passes=10, workers=2)\n",
        "    print(\"---------------------\" + name + \"---------------------\")\n",
        "    for idx, topic in cs_lda_model.print_topics(-1):\n",
        "        print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
        "        print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mpwWXOo9Nyob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1b8a93-1dfc-43f6-a7a1-0dee4195f5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------com.simplemobiletools.notes.pro---------------------\n",
            "Topic: 0 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"use\" + 0.001*\"simple\" + 0.001*\"note\" + 0.001*\"great\" + 0.001*\"like\" + 0.001*\"apps\" + 0.001*\"pro\" + 0.001*\"love\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.001*\"simple\" + 0.001*\"great\" + 0.001*\"use\" + 0.001*\"like\" + 0.001*\"apps\" + 0.001*\"easy\" + 0.001*\"list\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.047*\"app\" + 0.031*\"notes\" + 0.024*\"simple\" + 0.019*\"note\" + 0.019*\"use\" + 0.014*\"great\" + 0.011*\"like\" + 0.011*\"easy\" + 0.009*\"apps\" + 0.008*\"list\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"simple\" + 0.001*\"use\" + 0.001*\"note\" + 0.001*\"great\" + 0.001*\"like\" + 0.001*\"easy\" + 0.001*\"apps\" + 0.001*\"good\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"simple\" + 0.001*\"note\" + 0.001*\"use\" + 0.001*\"great\" + 0.001*\"easy\" + 0.001*\"like\" + 0.001*\"good\" + 0.001*\"apps\"\n",
            "\n",
            "\n",
            "---------------------com.bvblogic.nimbusnote---------------------\n",
            "Topic: 0 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.000*\"note\" + 0.000*\"evernote\" + 0.000*\"like\" + 0.000*\"good\" + 0.000*\"use\" + 0.000*\"great\" + 0.000*\"best\" + 0.000*\"nimbus\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.041*\"app\" + 0.024*\"notes\" + 0.020*\"note\" + 0.014*\"evernote\" + 0.012*\"good\" + 0.011*\"nimbus\" + 0.010*\"like\" + 0.010*\"great\" + 0.010*\"use\" + 0.007*\"best\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.043*\"app\" + 0.029*\"notes\" + 0.022*\"simple\" + 0.018*\"note\" + 0.017*\"use\" + 0.013*\"great\" + 0.010*\"like\" + 0.010*\"easy\" + 0.009*\"apps\" + 0.008*\"good\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.000*\"evernote\" + 0.000*\"nimbus\" + 0.000*\"like\" + 0.000*\"great\" + 0.000*\"good\" + 0.000*\"use\" + 0.000*\"best\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.001*\"use\" + 0.001*\"good\" + 0.000*\"great\" + 0.000*\"like\" + 0.000*\"love\" + 0.000*\"evernote\" + 0.000*\"simple\"\n",
            "\n",
            "\n",
            "---------------------com.rgiskard.fairnote---------------------\n",
            "Topic: 0 \n",
            "Words: 0.051*\"app\" + 0.029*\"notes\" + 0.020*\"note\" + 0.016*\"simple\" + 0.015*\"use\" + 0.014*\"great\" + 0.011*\"good\" + 0.010*\"like\" + 0.009*\"easy\" + 0.007*\"apps\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.001*\"app\" + 0.000*\"notes\" + 0.000*\"note\" + 0.000*\"good\" + 0.000*\"like\" + 0.000*\"use\" + 0.000*\"simple\" + 0.000*\"evernote\" + 0.000*\"great\" + 0.000*\"need\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.002*\"app\" + 0.002*\"notes\" + 0.001*\"note\" + 0.001*\"use\" + 0.001*\"simple\" + 0.001*\"great\" + 0.001*\"easy\" + 0.001*\"good\" + 0.001*\"love\" + 0.001*\"best\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"great\" + 0.000*\"note\" + 0.000*\"good\" + 0.000*\"use\" + 0.000*\"like\" + 0.000*\"simple\" + 0.000*\"evernote\" + 0.000*\"easy\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.041*\"app\" + 0.024*\"notes\" + 0.020*\"note\" + 0.014*\"evernote\" + 0.012*\"good\" + 0.010*\"nimbus\" + 0.010*\"great\" + 0.010*\"like\" + 0.010*\"use\" + 0.007*\"best\"\n",
            "\n",
            "\n",
            "---------------------com.transno.app---------------------\n",
            "Topic: 0 \n",
            "Words: 0.000*\"app\" + 0.000*\"notes\" + 0.000*\"note\" + 0.000*\"great\" + 0.000*\"use\" + 0.000*\"simple\" + 0.000*\"like\" + 0.000*\"good\" + 0.000*\"easy\" + 0.000*\"best\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.041*\"app\" + 0.027*\"notes\" + 0.021*\"simple\" + 0.017*\"note\" + 0.016*\"use\" + 0.012*\"great\" + 0.010*\"like\" + 0.009*\"easy\" + 0.008*\"apps\" + 0.007*\"good\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.040*\"app\" + 0.024*\"notes\" + 0.020*\"note\" + 0.013*\"evernote\" + 0.011*\"good\" + 0.010*\"nimbus\" + 0.010*\"great\" + 0.010*\"like\" + 0.010*\"use\" + 0.007*\"best\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"app\" + 0.000*\"notes\" + 0.000*\"note\" + 0.000*\"good\" + 0.000*\"use\" + 0.000*\"great\" + 0.000*\"like\" + 0.000*\"best\" + 0.000*\"simple\" + 0.000*\"love\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.059*\"app\" + 0.019*\"notes\" + 0.017*\"great\" + 0.014*\"note\" + 0.013*\"good\" + 0.012*\"use\" + 0.010*\"best\" + 0.010*\"love\" + 0.010*\"like\" + 0.009*\"simple\"\n",
            "\n",
            "\n",
            "---------------------com.dev.noteflow---------------------\n",
            "Topic: 0 \n",
            "Words: 0.001*\"app\" + 0.001*\"note\" + 0.001*\"notes\" + 0.000*\"use\" + 0.000*\"great\" + 0.000*\"love\" + 0.000*\"evernote\" + 0.000*\"good\" + 0.000*\"best\" + 0.000*\"like\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.059*\"app\" + 0.018*\"great\" + 0.013*\"notes\" + 0.012*\"love\" + 0.012*\"good\" + 0.012*\"best\" + 0.012*\"use\" + 0.010*\"mind\" + 0.010*\"note\" + 0.009*\"like\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.001*\"app\" + 0.001*\"notes\" + 0.001*\"note\" + 0.000*\"great\" + 0.000*\"use\" + 0.000*\"best\" + 0.000*\"good\" + 0.000*\"love\" + 0.000*\"like\" + 0.000*\"simple\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.000*\"app\" + 0.000*\"notes\" + 0.000*\"great\" + 0.000*\"good\" + 0.000*\"note\" + 0.000*\"use\" + 0.000*\"like\" + 0.000*\"best\" + 0.000*\"evernote\" + 0.000*\"love\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.047*\"app\" + 0.027*\"notes\" + 0.021*\"note\" + 0.012*\"use\" + 0.012*\"great\" + 0.012*\"good\" + 0.010*\"like\" + 0.009*\"simple\" + 0.007*\"best\" + 0.007*\"evernote\"\n",
            "\n",
            "\n",
            "---------------------com.appxy.planner---------------------\n",
            "Topic: 0 \n",
            "Words: 0.039*\"app\" + 0.023*\"notes\" + 0.019*\"note\" + 0.013*\"evernote\" + 0.011*\"good\" + 0.010*\"nimbus\" + 0.010*\"like\" + 0.010*\"great\" + 0.009*\"use\" + 0.006*\"best\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.049*\"app\" + 0.016*\"use\" + 0.014*\"love\" + 0.014*\"great\" + 0.013*\"like\" + 0.012*\"planner\" + 0.012*\"good\" + 0.012*\"calendar\" + 0.012*\"tasks\" + 0.010*\"easy\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.054*\"app\" + 0.019*\"notes\" + 0.017*\"great\" + 0.014*\"use\" + 0.013*\"note\" + 0.012*\"simple\" + 0.011*\"love\" + 0.011*\"good\" + 0.010*\"best\" + 0.010*\"like\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.002*\"app\" + 0.001*\"great\" + 0.001*\"note\" + 0.001*\"notes\" + 0.001*\"like\" + 0.000*\"use\" + 0.000*\"love\" + 0.000*\"best\" + 0.000*\"good\" + 0.000*\"easy\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.048*\"app\" + 0.023*\"notes\" + 0.018*\"note\" + 0.012*\"good\" + 0.012*\"great\" + 0.009*\"use\" + 0.009*\"simple\" + 0.008*\"like\" + 0.007*\"encryption\" + 0.006*\"best\"\n",
            "\n",
            "\n",
            "---------------------com.microsoft.todos---------------------\n",
            "Topic: 0 \n",
            "Words: 0.001*\"app\" + 0.001*\"great\" + 0.001*\"use\" + 0.000*\"good\" + 0.000*\"tasks\" + 0.000*\"like\" + 0.000*\"notes\" + 0.000*\"love\" + 0.000*\"best\" + 0.000*\"list\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.055*\"app\" + 0.017*\"use\" + 0.016*\"good\" + 0.016*\"great\" + 0.012*\"tasks\" + 0.011*\"love\" + 0.011*\"like\" + 0.011*\"easy\" + 0.009*\"list\" + 0.008*\"best\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.001*\"app\" + 0.000*\"good\" + 0.000*\"great\" + 0.000*\"love\" + 0.000*\"use\" + 0.000*\"like\" + 0.000*\"tasks\" + 0.000*\"list\" + 0.000*\"easy\" + 0.000*\"nice\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.003*\"app\" + 0.001*\"good\" + 0.001*\"use\" + 0.001*\"bir\" + 0.001*\"great\" + 0.001*\"list\" + 0.001*\"useful\" + 0.001*\"tasks\" + 0.001*\"day\" + 0.001*\"task\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.004*\"app\" + 0.001*\"good\" + 0.001*\"use\" + 0.001*\"great\" + 0.001*\"list\" + 0.001*\"tasks\" + 0.001*\"task\" + 0.001*\"easy\" + 0.001*\"love\" + 0.001*\"day\"\n",
            "\n",
            "\n",
            "---------------------com.time_management_studio.my_daily_planner---------------------\n",
            "Topic: 0 \n",
            "Words: 0.056*\"app\" + 0.019*\"good\" + 0.018*\"use\" + 0.017*\"great\" + 0.016*\"tasks\" + 0.015*\"list\" + 0.012*\"easy\" + 0.012*\"task\" + 0.010*\"day\" + 0.010*\"love\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.058*\"app\" + 0.025*\"good\" + 0.016*\"great\" + 0.015*\"use\" + 0.014*\"tasks\" + 0.012*\"easy\" + 0.012*\"love\" + 0.011*\"like\" + 0.009*\"day\" + 0.009*\"nice\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.051*\"app\" + 0.022*\"notes\" + 0.017*\"note\" + 0.014*\"great\" + 0.012*\"use\" + 0.012*\"good\" + 0.010*\"like\" + 0.008*\"best\" + 0.008*\"simple\" + 0.008*\"love\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.001*\"app\" + 0.000*\"great\" + 0.000*\"good\" + 0.000*\"like\" + 0.000*\"use\" + 0.000*\"notes\" + 0.000*\"love\" + 0.000*\"list\" + 0.000*\"easy\" + 0.000*\"tasks\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.047*\"app\" + 0.016*\"use\" + 0.014*\"love\" + 0.013*\"great\" + 0.012*\"like\" + 0.012*\"planner\" + 0.012*\"good\" + 0.012*\"calendar\" + 0.011*\"tasks\" + 0.009*\"easy\"\n",
            "\n",
            "\n",
            "---------------------ru.infteh.organizer.trial---------------------\n",
            "Topic: 0 \n",
            "Words: 0.001*\"app\" + 0.001*\"good\" + 0.001*\"great\" + 0.000*\"easy\" + 0.000*\"love\" + 0.000*\"use\" + 0.000*\"like\" + 0.000*\"best\" + 0.000*\"tasks\" + 0.000*\"day\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.002*\"app\" + 0.001*\"good\" + 0.001*\"love\" + 0.001*\"use\" + 0.001*\"bir\" + 0.001*\"great\" + 0.001*\"notes\" + 0.001*\"tasks\" + 0.001*\"like\" + 0.001*\"easy\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.049*\"app\" + 0.016*\"use\" + 0.015*\"love\" + 0.014*\"great\" + 0.014*\"calendar\" + 0.014*\"good\" + 0.013*\"like\" + 0.013*\"tasks\" + 0.011*\"day\" + 0.010*\"easy\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.035*\"app\" + 0.024*\"notes\" + 0.020*\"note\" + 0.011*\"evernote\" + 0.010*\"good\" + 0.009*\"great\" + 0.009*\"like\" + 0.008*\"nimbus\" + 0.008*\"use\" + 0.006*\"best\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.059*\"app\" + 0.019*\"good\" + 0.017*\"great\" + 0.017*\"use\" + 0.013*\"tasks\" + 0.012*\"easy\" + 0.012*\"list\" + 0.011*\"love\" + 0.010*\"like\" + 0.010*\"task\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "cs_stop_words=set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# THIS IS FOR THE OTHER COMPETITOR AND SIMILAR APPS\n",
        "data = pd.read_csv(\"MyAppDescriptions.csv\")\n",
        "package_names = data['Package Name']\n",
        "\n",
        "every_token = []\n",
        "# temporary_tokens = []\n",
        "for name in package_names:\n",
        "  if 'com.evernote' in name:\n",
        "    continue\n",
        "  else:\n",
        "    temporary_tokens = []\n",
        "    cs_review_list = pd.read_csv(name + '.csv')\n",
        "    cs_reviews = cs_review_list['Review']\n",
        "    for cs_review in cs_reviews:\n",
        "      cs_tokens = word_tokenize(str(cs_review))\n",
        "      for cs_token in cs_tokens:\n",
        "        temporary_tokens.append(cs_token)\n",
        "    cs_vect = TfidfVectorizer(stop_words=cs_stop_words,max_features=1000)\n",
        "    cs_vect_text=cs_vect.fit_transform(temporary_tokens)\n",
        "    _lda_model =  LatentDirichletAllocation(n_components=10, learning_method='online', random_state=42, max_iter=1)\n",
        "    cs_lda_top=_lda_model.fit_transform(cs_vect_text)\n",
        "    print(\"Document 0: \")\n",
        "    for i,topic in enumerate(cs_lda_top[0]):\n",
        "      print(\"Topic \",i,\": \",topic*100,\"%\")\n",
        "\n",
        "    vocab = cs_vect.get_feature_names()\n",
        "    for i, comp in enumerate(_lda_model.components_):\n",
        "      vocab_comp = zip(vocab, comp)\n",
        "      sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
        "      print(\"Topic \"+str(i)+\": \")\n",
        "      for t in sorted_words:\n",
        "        print(t[0],end=\" \")\n",
        "      print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfPwVprKaTi7",
        "outputId": "15d175b2-d025-44b4-a067-f1872a546107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 0: \n",
            "Topic  0 :  10.0 %\n",
            "Topic  1 :  10.0 %\n",
            "Topic  2 :  10.0 %\n",
            "Topic  3 :  10.0 %\n",
            "Topic  4 :  10.0 %\n",
            "Topic  5 :  10.0 %\n",
            "Topic  6 :  10.0 %\n",
            "Topic  7 :  10.0 %\n",
            "Topic  8 :  10.0 %\n",
            "Topic  9 :  10.0 %\n",
            "Topic 0: \n",
            "screen work old expected save lost cursor happy card separate \n",
            "\n",
            "Topic 1: \n",
            "perfect new option permissions quick useful file straightforward quality design \n",
            "\n",
            "Topic 2: \n",
            "easy im update add unnecessary solid want edit thousand application \n",
            "\n",
            "Topic 3: \n",
            "great widget ive version excellent taking thank time bought multiple \n",
            "\n",
            "Topic 4: \n",
            "like good pro nice reliable works looking folder worth txt \n",
            "\n",
            "Topic 5: \n",
            "app notes love source text stars buy background nova set \n",
            "\n",
            "Topic 6: \n",
            "simple apps list backup dont basic ads fix items able \n",
            "\n",
            "Topic 7: \n",
            "use need doesnt feature features reasons options right button settings \n",
            "\n",
            "Topic 8: \n",
            "note best developer files responsive installed simply special precisely far \n",
            "\n",
            "Topic 9: \n",
            "thanks open lists way checklist exactly tried import wish instead \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.000000017087385 %\n",
            "Topic  1 :  5.000000016312947 %\n",
            "Topic  2 :  5.000000017004185 %\n",
            "Topic  3 :  5.000000016401726 %\n",
            "Topic  4 :  5.000000014438639 %\n",
            "Topic  5 :  5.000000014610013 %\n",
            "Topic  6 :  5.0000000136905856 %\n",
            "Topic  7 :  5.000000017019364 %\n",
            "Topic  8 :  54.9999998575193 %\n",
            "Topic  9 :  5.000000015915866 %\n",
            "Topic 0: \n",
            "free taking account apps thing interface thanks device email years \n",
            "\n",
            "Topic 1: \n",
            "good phone nice lot excellent view folders looks thirty users \n",
            "\n",
            "Topic 2: \n",
            "use android work love version im easy doesnt data tried \n",
            "\n",
            "Topic 3: \n",
            "like desktop stars know point way wont не available на \n",
            "\n",
            "Topic 4: \n",
            "notes evernote great text offline sync want password simple line \n",
            "\n",
            "Topic 5: \n",
            "app features add right dont working hope login color chrome \n",
            "\n",
            "Topic 6: \n",
            "note option need feature perfect list adding onenote got needed \n",
            "\n",
            "Topic 7: \n",
            "better useful ive able easily looking writing replacement mode guys \n",
            "\n",
            "Topic 8: \n",
            "nimbus time update web title far screen application open editor \n",
            "\n",
            "Topic 9: \n",
            "best google folder search fix support windows awesome developer user \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.0000000014515145 %\n",
            "Topic  1 :  5.000000001788869 %\n",
            "Topic  2 :  5.00000000139846 %\n",
            "Topic  3 :  5.000000001753017 %\n",
            "Topic  4 :  5.000001082676218 %\n",
            "Topic  5 :  5.000000001692562 %\n",
            "Topic  6 :  54.999998904951376 %\n",
            "Topic  7 :  5.000000001597868 %\n",
            "Topic  8 :  5.000000001573459 %\n",
            "Topic  9 :  5.0000000011166525 %\n",
            "Topic 0: \n",
            "features ive text way support search little files able thank \n",
            "\n",
            "Topic 1: \n",
            "work password useful works user developer im lot far default \n",
            "\n",
            "Topic 2: \n",
            "notes like encryption clean options brilliant worth making immediately android \n",
            "\n",
            "Topic 3: \n",
            "simple nice backup dev google awesome excellent phone design fairnote \n",
            "\n",
            "Topic 4: \n",
            "add feature definitely better mode color drive thanks small quick \n",
            "\n",
            "Topic 5: \n",
            "use need got perfect amazing looking maybe bought dark lots \n",
            "\n",
            "Topic 6: \n",
            "note great encrypted dont new want widget theres updates functional \n",
            "\n",
            "Topic 7: \n",
            "taking apps option interface needs instead notepad sync job didnt \n",
            "\n",
            "Topic 8: \n",
            "easy best pro encrypt things problem going notification missing font \n",
            "\n",
            "Topic 9: \n",
            "app good love version fingerprint time thing checklist fantastic exactly \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.000033484594289 %\n",
            "Topic  1 :  5.000027336234066 %\n",
            "Topic  2 :  5.00003396214487 %\n",
            "Topic  3 :  5.00003322592748 %\n",
            "Topic  4 :  5.000029494394368 %\n",
            "Topic  5 :  5.000033491006447 %\n",
            "Topic  6 :  5.000033211438737 %\n",
            "Topic  7 :  54.99970947086271 %\n",
            "Topic  8 :  5.000037594915389 %\n",
            "Topic  9 :  5.000028728481647 %\n",
            "Topic 0: \n",
            "simple taking transno im word design maps cool landscape beta \n",
            "\n",
            "Topic 1: \n",
            "app like useful perfect free text hope bullet adding favorite \n",
            "\n",
            "Topic 2: \n",
            "good features apps far point interface wish team line experience \n",
            "\n",
            "Topic 3: \n",
            "awesome amazing option want thanks super thoughts write data support \n",
            "\n",
            "Topic 4: \n",
            "love mind best easy folder definitely help things makes kind \n",
            "\n",
            "Topic 5: \n",
            "note ive clean list time ideas theres outline la access \n",
            "\n",
            "Topic 6: \n",
            "notes map need mindmap ui dont lot application looking day \n",
            "\n",
            "Topic 7: \n",
            "work version organize functionality options able bit user wonderful devs \n",
            "\n",
            "Topic 8: \n",
            "feature making new way works thank recommend create templates highly \n",
            "\n",
            "Topic 9: \n",
            "great use add nice mapping better excellent mode type helps \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.001376588709777 %\n",
            "Topic  1 :  5.001389808256845 %\n",
            "Topic  2 :  5.001244757927976 %\n",
            "Topic  3 :  5.001395224211282 %\n",
            "Topic  4 :  5.001363423441073 %\n",
            "Topic  5 :  54.988363215396 %\n",
            "Topic  6 :  5.001156976212826 %\n",
            "Topic  7 :  5.001148733233468 %\n",
            "Topic  8 :  5.001076208030684 %\n",
            "Topic  9 :  5.0014850645800735 %\n",
            "Topic 0: \n",
            "bire alma uygulaması good için useful notes app çok bir \n",
            "\n",
            "Topic 1: \n",
            "güzel sadelik sevenler useful app bire uygulaması bir çok alma \n",
            "\n",
            "Topic 2: \n",
            "app için çok güzel uygulaması good backup useful sadelik bir \n",
            "\n",
            "Topic 3: \n",
            "sevenler bir çok alma için useful uygulaması bire backup güzel \n",
            "\n",
            "Topic 4: \n",
            "çok için backup bir notes uygulaması useful sadelik güzel app \n",
            "\n",
            "Topic 5: \n",
            "useful backup bire bir app sadelik alma çok için uygulaması \n",
            "\n",
            "Topic 6: \n",
            "good uygulaması alma güzel çok için sevenler bire sadelik bir \n",
            "\n",
            "Topic 7: \n",
            "sadelik backup app sevenler çok bir için notes güzel bire \n",
            "\n",
            "Topic 8: \n",
            "uygulaması çok app backup güzel sadelik sevenler bir alma bire \n",
            "\n",
            "Topic 9: \n",
            "bir notes useful bire çok good backup alma app için \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.0000000082729 %\n",
            "Topic  1 :  5.000000009038072 %\n",
            "Topic  2 :  5.000000008804891 %\n",
            "Topic  3 :  5.000000008819759 %\n",
            "Topic  4 :  5.000000008444732 %\n",
            "Topic  5 :  5.000000008149151 %\n",
            "Topic  6 :  5.0000000086417895 %\n",
            "Topic  7 :  5.00000000808514 %\n",
            "Topic  8 :  54.99999992408222 %\n",
            "Topic  9 :  5.000000007661347 %\n",
            "Topic 0: \n",
            "tasks dont organized best features awesome widgets life feature new \n",
            "\n",
            "Topic 1: \n",
            "task version notes sync ive week want wish paid amazing \n",
            "\n",
            "Topic 2: \n",
            "need schedule doesnt looking daily thing better fix date screen \n",
            "\n",
            "Topic 3: \n",
            "great like planner far update download problem reminders makes says \n",
            "\n",
            "Topic 4: \n",
            "good events time google useful free open little change long \n",
            "\n",
            "Topic 5: \n",
            "app widget apps account stuff wont interface recurring carry times \n",
            "\n",
            "Topic 6: \n",
            "easy nice set way track lot user create busy loved \n",
            "\n",
            "Topic 7: \n",
            "work phone works im view event color note needs stars \n",
            "\n",
            "Topic 8: \n",
            "day helps add things thanks got upgrade pay weekly tablet \n",
            "\n",
            "Topic 9: \n",
            "love use calendar simple keeps perfect helpful able try option \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.000000000037874 %\n",
            "Topic  1 :  5.00000000004639 %\n",
            "Topic  2 :  54.999999999618254 %\n",
            "Topic  3 :  5.000000000042037 %\n",
            "Topic  4 :  5.000000000042571 %\n",
            "Topic  5 :  5.0000000000448 %\n",
            "Topic  6 :  5.000000000036693 %\n",
            "Topic  7 :  5.000000000043289 %\n",
            "Topic  8 :  5.000000000044951 %\n",
            "Topic  9 :  5.000000000043134 %\n",
            "Topic 0: \n",
            "list love nice helpful perfect features dont amazing wish keeps \n",
            "\n",
            "Topic 1: \n",
            "need reminders date outlook help makes items update different completed \n",
            "\n",
            "Topic 2: \n",
            "good task option set im life application manage view tool \n",
            "\n",
            "Topic 3: \n",
            "tasks easy microsoft works helps way sync google needs plan \n",
            "\n",
            "Topic 4: \n",
            "best lists awesome feature calendar doesnt ive lot working thing \n",
            "\n",
            "Topic 5: \n",
            "time work want account new needed repeat windows remember overall \n",
            "\n",
            "Topic 6: \n",
            "app day simple todo phone notes getting week version sort \n",
            "\n",
            "Topic 7: \n",
            "great better things daily reminder wunderlist ui days nan fantastic \n",
            "\n",
            "Topic 8: \n",
            "use like add widget excellent organized user share thanks super \n",
            "\n",
            "Topic 9: \n",
            "useful apps track far devices thank complete notification able stars \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.000000000332736 %\n",
            "Topic  1 :  5.000000001089936 %\n",
            "Topic  2 :  5.000000000324405 %\n",
            "Topic  3 :  5.000000000313528 %\n",
            "Topic  4 :  5.000000000332096 %\n",
            "Topic  5 :  5.000000000349858 %\n",
            "Topic  6 :  54.999999996233804 %\n",
            "Topic  7 :  5.000000000326848 %\n",
            "Topic  8 :  5.000000000364993 %\n",
            "Topic  9 :  5.000000000331787 %\n",
            "Topic 0: \n",
            "task work things reminders complete pretty organize think didnt problem \n",
            "\n",
            "Topic 1: \n",
            "use love want days able thats way paid upgrade worth \n",
            "\n",
            "Topic 2: \n",
            "day planner daily add wish reminder tried option keeps wanted \n",
            "\n",
            "Topic 3: \n",
            "tasks simple time useful excellent ive calendar ads feature track \n",
            "\n",
            "Topic 4: \n",
            "best helpful apps helps better pay doesnt plan buy schedule \n",
            "\n",
            "Topic 5: \n",
            "far pro set im exactly life perfect working change date \n",
            "\n",
            "Topic 6: \n",
            "app good easy like nice works organized help place available \n",
            "\n",
            "Topic 7: \n",
            "great looking recurring google planning thousand friendly sync basic ok \n",
            "\n",
            "Topic 8: \n",
            "list awesome dont free thank application phone user thing know \n",
            "\n",
            "Topic 9: \n",
            "need version features amazing recommend lists everyday week stars different \n",
            "\n",
            "Document 0: \n",
            "Topic  0 :  5.000000001521147 %\n",
            "Topic  1 :  5.000000001535219 %\n",
            "Topic  2 :  5.0000000015137305 %\n",
            "Topic  3 :  5.000000001682295 %\n",
            "Topic  4 :  5.000000001510236 %\n",
            "Topic  5 :  5.000000001378749 %\n",
            "Topic  6 :  54.99999998627655 %\n",
            "Topic  7 :  5.00000000144852 %\n",
            "Topic  8 :  5.000000001447053 %\n",
            "Topic  9 :  5.000000001686498 %\n",
            "Topic 0: \n",
            "day like simple daily thanks view needs options reminders month \n",
            "\n",
            "Topic 1: \n",
            "tasks better ive want tried keeps repeat look worth right \n",
            "\n",
            "Topic 2: \n",
            "great google phone wish date friendly track downloaded appoftheday problem \n",
            "\n",
            "Topic 3: \n",
            "use love work schedule exactly calendars try tablet hours organizer \n",
            "\n",
            "Topic 4: \n",
            "calendar apps useful far think new lot little helps help \n",
            "\n",
            "Topic 5: \n",
            "task widget nice excellent works appointments calender needed search change \n",
            "\n",
            "Topic 6: \n",
            "app need events syncs days paid awesome user application functionality \n",
            "\n",
            "Topic 7: \n",
            "good easy version time dont planner thank features helpful widgets \n",
            "\n",
            "Topic 8: \n",
            "free best looking way list sync pro event perfect life \n",
            "\n",
            "Topic 9: \n",
            "add im doesnt able screen option different things job color \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus For Task 4\n",
        "Please find below the topics that has the highest percentage contribution in the assigned app reviews:\n",
        "- Topic 7: update years able try paid mobile closes crash google interface\n",
        "\n",
        "Please find the top 10 reviews printed below. The way I have chosen these reviews is by using the words in the topics, and if the words exist in the reviews then i extract them. The rest are discarded. These ten reviews, in my opinion, after manual inspection, summarize the root of the problem, which is that the users are not happy with the update evernote went through. They were used to the old one and now think that this new version is problematic. User experience is very important when using software, so this is why i think that these reviews must be handled with care, and they should make the app as easy to use for the user and easy to get used to the new changes."
      ],
      "metadata": {
        "id": "2DlQ3Aogxktu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews_list = pd.read_csv('com.evernote.csv')\n",
        "reviews = reviews_list['Review']\n",
        "\n",
        "word_list = ['update', 'years', 'able', 'try', 'paid', 'mobile', 'closes', 'crash', 'google', 'interface']\n",
        "\n",
        "reviews_print = []\n",
        "for word in word_list:\n",
        "  for review in reviews:\n",
        "    if word in str(review):\n",
        "      reviews_print.append(review)\n",
        "\n",
        "print(len(reviews_print))\n",
        "for i in reviews_print[:10]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "xbtH0VMNxmvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bee80d-9703-4add-9a21-5ebf1d9f7457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5116\n",
            "use years year user experience android app awful ux worse years ago click takes seconds new screen add note phone send email evernote account address gmail faster entering new note evernote android app updates didnt improve thing search feature app useless pc app works shame\n",
            "hey dev king notes ya know ive like decade heck happened idk bring previous version android b4 bs update cmon devs loved u guys app\n",
            "ive app years years usually good year updates notes usually create brand new duplicate notes double check versions deleting instance like overall organization layout things havent switched app duplicate notes annoying\n",
            "update thousand, twenty-two uninstalled reinstalled app app opensbut attachmentsvoice memos documents basically attached wont open play years worth stuff gone goto app years like update app starts issues havent able app day today keeps closing soon try start frustratingespecially notes\n",
            "lost bunch notes updates\n",
            "retry thousand twenty-two runs registration giving worthless free version update constantly hanging thing works request report including logs payed testers dont mind anger stress management throwing precious phone walls damned evernote hangs loose notes hours work damn u evernote hours work amateurs going works\n",
            "crashing samsung s22 ui fifty notes urgent situation update reinstalled evernote advice working fine tks\n",
            "evernote great seemingly lost ethos supporting existing power users developers intent phasing constant updates add bloat annoying new features abandoning simple flexible ui brought users platform place look recent reviews youll complaints repeated\n",
            "updated review evernote thousand loved happy pay premium nov thousand twenty-two unusable especially android duplication losing notes saving slow wont open notes circle death search working googling tried uninstalling phone reinstalled pick fix version properly works properly relief huge confidence loss releases clearly tested properly happens ill\n",
            "terrible mobile impossible add tags saving note doesnt work frustrating update bad unbelievable\n",
            "updated night making note kept closing keyboard noww open note blank new interface makes chunky hard work recently opened note recently opened notes hell suggested notes shows irrelevant notes wish simple version\n",
            "use app daily latest update causing constantly crash says app error reinstall developer fixes uninstalled reinstalled change use passcode crashes fix\n",
            "pros works cons version conflict resolution exist text formatting function sucks newer versions worse older ones example old version thousand worked text notes flawlessly starting thousand twenty-one update app handle plaint text note larger kbytes keeps freezing app keeps quitting note edit mode randomly expressly annoying premium price ridiculously high sum looks acts beta product\n",
            "tablet app updated thousand checklists bullets dont work anymore tablet app probably todo paid feature im paying user im planning bail actually kept date id working software broken premium features\n",
            "app years finding new updates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5\n",
        "## Discussion\n",
        "The following enhancements can be done in the app:\n",
        "1. They can add a feature where whatever you write using a touchpen or a finger can be converted into text. I have used this features in one of my notes app that I use, and its pretty useful and looks nice too.\n",
        "2. Another one would be to categorize my notes based on subjects. I use evernote a lot, and i have my schedules, my grocery lists, random passwords, notes, and whatnot stored on there. It would be nice if i could categorize them so that I can find my notes daster.\n",
        "## Bonus Discussion\n",
        "1. https://github.com/evernote/evernote-sdk-ios/issues/107\n",
        "2. https://github.com/evernote/evernote-sdk-ios/issues/108"
      ],
      "metadata": {
        "id": "f55iNOXmxnLS"
      }
    }
  ]
}